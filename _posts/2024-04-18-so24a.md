---
title: " Optimising Distributions with Natural Gradient Surrogates "
software: " https://github.com/cambridge-mlg/sngd "
abstract: " Natural gradient methods have been used to optimise the parameters of
  probability distributions in a variety of settings, often resulting in fast-converging
  procedures. Unfortunately, for many distributions of interest, computing the natural
  gradient has a number of challenges. In this work we propose a novel technique for
  tackling such issues, which involves reframing the optimisation as one with respect
  to the parameters of a surrogate distribution, for which computing the natural gradient
  is easy. We give several examples of existing methods that can be interpreted as
  applying this technique, and propose a new method for applying it to a wide variety
  of problems. Our method expands the set of distributions that can be efficiently
  targeted with natural gradients. Furthermore, it is fast, easy to understand, simple
  to implement using standard autodiff software, and does not require lengthy model-specific
  derivations. We demonstrate our method on maximum likelihood estimation and variational
  inference tasks. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: so24a
month: 0
tex_title: " Optimising Distributions with Natural Gradient Surrogates "
firstpage: 2224
lastpage: 2232
page: 2224-2232
order: 2224
cycles: false
bibtex_author: So, Jonathan and E. Turner, Richard
author:
- given: Jonathan
  family: So
- given: Richard
  family: E. Turner
date: 2024-04-18
address:
container-title: Proceedings of The 27th International Conference on Artificial Intelligence
  and Statistics
volume: '238'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 18
pdf: https://proceedings.mlr.press/v238/so24a/so24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
